{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8631289,"sourceType":"datasetVersion","datasetId":5168143},{"sourceId":8637957,"sourceType":"datasetVersion","datasetId":5172829},{"sourceId":8640154,"sourceType":"datasetVersion","datasetId":5174419},{"sourceId":8644672,"sourceType":"datasetVersion","datasetId":5177366},{"sourceId":8735239,"sourceType":"datasetVersion","datasetId":5243684},{"sourceId":8755155,"sourceType":"datasetVersion","datasetId":5259509},{"sourceId":8759132,"sourceType":"datasetVersion","datasetId":5262429},{"sourceId":8764553,"sourceType":"datasetVersion","datasetId":5266236},{"sourceId":8772888,"sourceType":"datasetVersion","datasetId":5272276},{"sourceId":8773604,"sourceType":"datasetVersion","datasetId":5272834},{"sourceId":8775506,"sourceType":"datasetVersion","datasetId":5274254},{"sourceId":8776062,"sourceType":"datasetVersion","datasetId":5274669},{"sourceId":8995016,"sourceType":"datasetVersion","datasetId":5418002}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport copy\nfrom tqdm import tqdm\nimport requests\nfrom PIL import Image \n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms.functional import to_tensor\nfrom torchvision import transforms as TF\nimport torch.nn.functional as F\nfrom torch.optim import AdamW\n\nfrom transformers import SegformerForSemanticSegmentation\nfrom transformers import get_scheduler\n\nfrom sklearn.metrics import jaccard_score\n\nclass BDDDataset(Dataset):\n    def __init__(self, images_dir, masks_dir, transform=None, num_images=None):\n        self.images_dir = images_dir\n        self.masks_dir = masks_dir\n        self.transform = transform\n        self.images = [img for img in os.listdir(images_dir) if img.endswith('.jpg')]\n\n        # Ensure the dataset has the same number of images and masks\n        if num_images:\n            if num_images > len(self.images):\n                print(f\"Requested {num_images} images, but only {len(self.images)} available. Using all available images.\")\n            else:\n                self.images = self.images[:num_images]\n\n        self.masks = [img.replace('.jpg', '.png') for img in self.images]\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image_path = os.path.join(self.images_dir, self.images[idx])\n        mask_path = os.path.join(self.masks_dir, self.masks[idx])\n        image = Image.open(image_path).convert(\"RGB\")\n        mask = Image.open(mask_path)  # Do not convert to grayscale\n\n        # Convert mask to numpy array\n        mask = np.array(mask)\n        \n        # Convert to PIL Image for consistency in transforms\n        mask = Image.fromarray(mask)\n\n        if self.transform:\n            image = self.transform(image)\n\n        mask = mask.resize((360, 640), resample=Image.NEAREST)\n        mask = np.array(mask)\n        \n        mask = torch.tensor(mask, dtype=torch.long)\n        \n        return image, mask\n\ndef mean_iou(preds, labels, num_classes):\n    # Flatten predictions and labels\n    preds_flat = preds.view(-1)\n    labels_flat = labels.view(-1)\n\n    # Check that the number of elements in the flattened predictions\n    # and labels are equal\n    if preds_flat.shape[0] != labels_flat.shape[0]:\n        raise ValueError(f\"Predictions and labels have mismatched shapes: \"\n                         f\"{preds_flat.shape} vs {labels_flat.shape}\")\n\n    # Calculate the Jaccard score for each class\n    iou = jaccard_score(labels_flat.cpu().numpy(), preds_flat.cpu().numpy(),\n                        average=None, labels=range(num_classes))\n\n    # Return the mean IoU\n    return np.mean(iou)\n\ndef mean_iou(preds, labels, num_classes):\n    # Flatten predictions and labels\n    preds_flat = preds.view(-1)\n    labels_flat = labels.view(-1)\n\n    # Check that the number of elements in the flattened predictions\n    # and labels are equal\n    if preds_flat.shape[0] != labels_flat.shape[0]:\n        raise ValueError(f\"Predictions and labels have mismatched shapes: \"\n                         f\"{preds_flat.shape} vs {labels_flat.shape}\")\n\n    # Calculate the Jaccard score for each class\n    iou = jaccard_score(labels_flat.cpu().numpy(), preds_flat.cpu().numpy(),\n                        average=None, labels=range(num_classes))\n\n    # Return the mean IoU\n    return np.mean(iou)\n\n# Define the appropriate transformations\ntransform = TF.Compose([\n    TF.Resize((360, 640)),\n    TF.ToTensor(),\n    TF.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Create the dataset with the specified number of images\ntrain_dataset = BDDDataset(images_dir='/kaggle/input/kltnsjsj/drivable_area/train/images',\n                           masks_dir='/kaggle/input/kltnsjsj/drivable_area/train/mask',\n                           transform=transform,\n                           num_images=3000)\n\nvalid_dataset = BDDDataset(images_dir='/kaggle/input/kltnsjsj/drivable_area/val/images',\n                           masks_dir='/kaggle/input/kltnsjsj/drivable_area/val/mask',\n                           transform=transform,\n                           num_images=1000)\n\n# Create the data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=6)\nvalid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False, num_workers=6)\n\n# Load the pre-trained model\nmodel = SegformerForSemanticSegmentation.from_pretrained('nvidia/segformer-b3-finetuned-ade-512-512')\n\n# Adjust the number of classes for BDD dataset\nmodel.config.num_labels = 3  # Replace with the actual number of classes\n\n\n# Check for CUDA acceleration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\n# Define the optimizer\noptimizer = AdamW(model.parameters(), lr=5e-5)\n\n# Define the learning rate scheduler\nnum_epochs = 5\nnum_training_steps = num_epochs * len(train_loader)\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps\n)\n\n# Placeholder for best mean IoU and best model weights\nbest_iou = 0.0\nbest_model_wts = copy.deepcopy(model.state_dict())\n\n# Lists to store the loss values\ntrain_losses = []\nvalid_ious = []\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_iterator = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\")\n    epoch_train_loss = 0.0\n\n    for batch in train_iterator:\n        images, masks = batch\n        images = images.to(device)\n        masks = masks.to(device).long()  # Ensure masks are LongTensors\n\n        # Remove the channel dimension from the masks tensor\n        masks = masks.squeeze(1)  # This changes the shape from [batch, 1, H, W] to [batch, H, W]\n        optimizer.zero_grad()\n\n        # Pass pixel_values and labels to the model\n        outputs = model(pixel_values=images, labels=masks, return_dict=True)\n        \n        loss = outputs[\"loss\"]\n        loss.backward()\n\n        optimizer.step()\n        lr_scheduler.step()\n        outputs = F.interpolate(outputs[\"logits\"], size=masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n        \n        epoch_train_loss += loss.item()\n        train_iterator.set_postfix(loss=loss.item())\n\n    avg_train_loss = epoch_train_loss / len(train_loader)\n    train_losses.append(avg_train_loss)\n\n    # Evaluation loop for each epoch\n    model.eval()\n    total_iou = 0\n    num_batches = 0\n    valid_iterator = tqdm(valid_loader, desc=\"Validation\", unit=\"batch\")\n\n    for batch in valid_iterator:\n        images, masks = batch\n        images = images.to(device)\n        masks = masks.to(device).long()\n    \n        with torch.no_grad():\n            # Get the logits from the model and apply argmax to get the predictions\n            outputs = model(pixel_values=images, return_dict=True)\n            outputs = F.interpolate(outputs[\"logits\"], size=masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n            preds = torch.argmax(outputs, dim=1)\n            preds = torch.unsqueeze(preds, dim=1)\n\n        preds = preds.view(-1)\n        masks = masks.view(-1)\n    \n        # Compute IoU\n        iou = mean_iou(preds, masks, model.config.num_labels)\n        total_iou += iou\n        num_batches += 1\n        valid_iterator.set_postfix(mean_iou=iou)\n    \n    epoch_iou = total_iou / num_batches\n    valid_ious.append(epoch_iou)\n    print(f\"Epoch {epoch+1}/{num_epochs} - Mean IoU: {epoch_iou:.4f}\")\n\n    # Check for improvement\n    if epoch_iou > best_iou:\n        print(f\"Validation IoU improved from {best_iou:.4f} to {epoch_iou:.4f}\")\n        best_iou = epoch_iou\n        best_model_wts = copy.deepcopy(model.state_dict())\n        torch.save(best_model_wts, '/kaggle/working/best_model.pth')\n\n# After all epochs, load the best model weights - optional\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T04:24:58.552728Z","iopub.execute_input":"2024-07-20T04:24:58.553663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label='Training Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(valid_ious, label='Validation IoU')\nplt.xlabel('Epoch')\nplt.ylabel('Mean IoU')\nplt.title('Validation Mean IoU')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-24T14:36:07.147852Z","iopub.execute_input":"2024-06-24T14:36:07.148658Z","iopub.status.idle":"2024-06-24T14:36:07.662875Z","shell.execute_reply.started":"2024-06-24T14:36:07.14862Z","shell.execute_reply":"2024-06-24T14:36:07.66199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}